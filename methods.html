<!DOCTYPE html>
 <html>
 	<head>
 		<meta charset="utf-8">
 		<meta http-equiv="X-UA-Compatible" content="IE=edge">
 		<title>Usability Research</title>
 		<meta name="description" content="A usability report for COMP210" />
 		<meta name="author" content="Alcwyn Parker" />
 		<meta name="HandheldFriendly" content="true" />
 		<meta name="MobileOptimized" content="320" />

    <!-- Use maximum-scale and user-scalable at your own risk. It disables pinch/zoom. Think about usability/accessibility before including.-->
 		<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
 		<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->
 		<link rel="stylesheet" type="text/css" href="css/main.css">
         <link href="https://fonts.googleapis.com/css?family=Crimson+Text" rel="stylesheet">
 	</head>
 	<body>

    <div class="main-container">
        <header id="top"></header>
        <div class="content">

            <aside>
                <nav>
                    <ul>
                        <li><a href="index.html">Introduction </a></li>
                        <li><a class="selected" href="methods.html">Methods </a></li>
                        <li><a href="results.html">Results </a></li>
                        <li><a href="discussion.html">Discussion </a></li>
                        <li><a href="conclusion.html">Conclusion </a></li>
                        <li><a href="#top">Top Of Page</a></li>
                    </ul>
                </nav>
            </aside>

            <section>
                <h1>Methods</h1>
            </section>
            <section>
                <mainTextc>
                    To gather the data on how consumers use the Battle Screen interface I employed 2 qualitative methods and one quantitative.
                    I performed all three in one sit down session.
                    To begin, I found two willing participants to play my game.
                    I then proceeded to get up the in-game instructions, after this point, it was up to them play the game.
                </mainTextc>
                <img src="images/topdown1.png" alt="topdown1.png" align="right" style="width:35%" />
                <mainText>
                    <h2>Observation</h2>  The observation stage began as soon as the participants received the phone.

                    During play, I noted any observations down on a paper notepad.

                    With a more traditional keyboard and mouse game, where there is only one person playing on one screen, observation is much easier.

                    Trying to effectively observe two people at the same time was difficult, at best.
                    Additionally, the nature of a touchscreen meant that even more of the screen was covered by the participant's fingers. As can be seen by the image on the right.

                    One possible solution would be to record using a camera. When asked I asked if I could film them playing the responses were negative.

                    To overcome the problems mentioned above, I used the inbuilt IOS screen recorder.

                    While I cannot see how the players react, I can see how the participants interacted with the screen.

                    The results on my notepad motivated what I looked for when viewing the screen recordings.
                </mainText>
               
            </section>
            <section>
                <mainTextc>
                    <h2>Quantitative: Questionaire</h2>
                    When deciding how I would gather the quantitative part of this study the immediate answer that came to mind was a digital questionnaire.
                    I, however, did not take this approach, instead, I decided to gather the quantitative part of my data before my interview.
                    The reason I got the participants to answer the questionnaire in person rather than online is so that I could explain to them the scaling system, this way I could avoid any confusion.
                    The downside being that participants are more likely to give a more complimentary score because they know they're talking to the creator of the game.
                    Most did not want to offer what they perceive to be an insult.
                    Through outsourcing, this kind of data bias may be removed.
                </mainTextc>
                <mainTextc>
                    <h2>Interview</h2>
                    During this part of the interview, I asked the participants open, optional questions.
                    The reason for making the questions optional was to not force the participant to make an opinion.
                    I feel this way the replies I got back were more relevant to the user's experience.
                    However, this does mean that my data set is not as complete as it would be otherwise.
                    By conducting a more conversational interview I hoped that the participants would offer useful information that could be useful to know, but I had not thought to ask.<a href="https://books.google.co.uk/books?id=MjNGDgAAQBAJ&printsec=frontcover#v=onepage&q&f=false">Page 146</a> 
                </mainTextc>
            </section>
        </div>
        <footer>
            [Tristan Barlow-Griffin] - 2017     <a href="https://itunes.apple.com/us/app/battle-screens-multiplayer-shooter/id1265632895?mt=8">AppStore</a>  <a href="https://github.com/TristanBarlow/comp210-interface-evaluation">GitRepo</a>
        </footer>
    </div>
 	</body>
 </html>
